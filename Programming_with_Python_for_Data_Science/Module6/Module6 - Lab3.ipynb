{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module6- Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is intentionally missing! Read the directions on the course lab page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import Normalizer, MaxAbsScaler,MinMaxScaler, KernelCenterer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import  Isomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--INFO : Goals for this assignment are first to see if it's possible to differentiate between people who have **Parkinson's** and who don't using **SciKit-Learn's support vector classifier**, \n",
    "and then to take a first-stab at a naive way of fine-tuning your parameters in an attempt to maximize the accuracy of your testing set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Load up the wheat dataset into dataframe 'X'\n",
    "# Verify you did it properly.\n",
    "# drop the name column.\n",
    "# Splice out the status column into a variable y and delete it from X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer    ...     \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374    ...      \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134    ...      \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233    ...      \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492    ...      \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425    ...      \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('./Datasets/parkinsons.data')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.drop('name', axis = 1) \n",
    "y = X.status\n",
    "X = X.drop('status' , axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform a train/test split. 30% test group size, with a random_state equal to 7\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.813559322034\n"
     ]
    }
   ],
   "source": [
    "#Create a SVC classifier. \n",
    "#Don't specify any parameters, just leave everything as default. \n",
    "#Fit it against your training data and then score your testing data\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "print (\"Score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Units on columns: Hz, %, Abs, dB, etc. With all of those units interacting with one another, \n",
    "some pre-processing is surely in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SciKit-Learn's pre-processing code. various pre-processors one at a time, \n",
    "#checking to see if they improve your predictive accuracy.\n",
    "\n",
    "#Experiment with Normalizer(), MaxAbsScaler(), MinMaxScaler(), KernelCenterer(), and StandardScaler().\n",
    "#norm = Normalizer()\n",
    "#X_train = norm.fit_transform(X_train)\n",
    "#X_test = norm.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)\n",
    "#max_abs= MaxAbsScaler()\n",
    "#X_train = max_abs.fit_transform(X_train)\n",
    "#X_test = max_abs.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)\n",
    "#min_max = MinMaxScaler()\n",
    "#X_train = min_max.fit_transform(X_train)\n",
    "#X_test = min_max.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_sc = StandardScaler()\n",
    "X_train = std_sc.fit_transform(X_train)\n",
    "X_test = std_sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: {} 0.932203389831\n"
     ]
    }
   ],
   "source": [
    "# Immediately after you do the pre-processing, run PCA on your dataset. \n",
    "# The original dataset has 22 columns and 1 label column. So try experimenting with PCA n_component values between 4 and 14.\n",
    "best_score = 0\n",
    "for n_components in range(4, 15):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    X_train2 = pca.transform(X_train)\n",
    "    X_test2 = pca.transform(X_test)\n",
    "    for C in np.arange(0.05, 2, 0.05):\n",
    "        for gamma in np.arange(0.001, 0.1, 0.001):\n",
    "                model = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "                model.fit(X_train2, y_train) \n",
    "                score = model.score(X_test2, y_test) \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "print ('Best score: {}', best_score)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Program a naive, best-parameter search by creating nested for-loops. \n",
    "#The outer for-loop should iterate a variable C from 0.05 to 2, using 0.05 unit increments. \n",
    "#The inner for-loop should increment a variable gamma from 0.001 to 0.1, using 0.001 unit increments. \n",
    "#As you know, Python ranges won't allow for float intervals, use np.arange\n",
    "#Since the goal is to find the parameters that result in the model having the best accuracy score, \n",
    "#you'll need a best_score = 0 variable that you initialize outside of the for-loops. Inside the inner for-loop, create an SVC model and pass in the C and gamma parameters its class constructor. \n",
    "#Train and score the model appropriately. If the current best_score is less than the model's score, update the best_score being sure to print it out, along with the C and gamma values that resulted in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gammas = np.arange(0.001, 0.1001, 0.001)\n",
    "Cs = np.arange(0.05, 2.05, 0.05)\n",
    "best_score = 0\n",
    "C_final = 0\n",
    "gamma_final =0\n",
    "\n",
    "for C in Cs:\n",
    "    for gamma in gammas:\n",
    "        model = SVC(C=C, gamma=gamma)\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            C_final = C\n",
    "            gamma_final = gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final C: 1.5000000000000002\n",
      "Final gamma: 0.1\n",
      "Best score: 0.9322033898305084\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)\n",
    "svc = SVC(C= C_final, gamma= gamma_final).fit(X_train,y_train)\n",
    "print('Final C: {}\\nFinal gamma: {}\\nBest score: {}'.format(svc.C, svc.gamma, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final C: 0.05\n",
      "Final gamma: 0.001\n",
      "Best score: 0.7966101694915254\n"
     ]
    }
   ],
   "source": [
    "# Using Normalizer for pre-processing without PCA\n",
    "#svc = SVC(C= C_final, gamma= gamma_final).fit(X_train,y_train)\n",
    "#print('Final C: {}\\nFinal gamma: {}\\nBest score: {}'.format(svc.C, svc.gamma, best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final C: 0.05\n",
      "Final gamma: 0.001\n",
      "Best score: 0.7966101694915254\n"
     ]
    }
   ],
   "source": [
    "# Using MaxAbsScaler for pre-processing without PCA\n",
    "svc = SVC(C= C_final, gamma= gamma_final).fit(X_train,y_train)\n",
    "print('Final C: {}\\nFinal gamma: {}\\nBest score: {}'.format(svc.C, svc.gamma, best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final C: 0.05\n",
      "Final gamma: 0.001\n",
      "Best score: 0.7966101694915254\n"
     ]
    }
   ],
   "source": [
    "# Using MinMaxScaler for pre-processing without PCA\n",
    "svc = SVC(C= C_final, gamma= gamma_final).fit(X_train,y_train)\n",
    "print('Final C: {}\\nFinal gamma: {}\\nBest score: {}'.format(svc.C, svc.gamma, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In the same spot, run Isomap on the data. \n",
    "#Manually experiment with every inclusive combination of n_neighbors between 2 and 5, and n_components between 4 and 6.\n",
    "#Are you able to get a better accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.949152542373\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for n_neighbors in range(2,6):\n",
    "    for n_components in range(4, 7):\n",
    "        isomap = Isomap(n_neighbors = n_neighbors, n_components=n_components)\n",
    "        isomap.fit(X_train)\n",
    "        X_train2 = isomap.transform(X_train)\n",
    "        X_test2 = isomap.transform(X_test)\n",
    "    for C in np.arange(0.05, 2, 0.05):\n",
    "        for gamma in np.arange(0.001, 0.1, 0.001):\n",
    "                model = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "                model.fit(X_train2, y_train) \n",
    "                score = model.score(X_test2, y_test) \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "print ('Best score: ', best_score)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
